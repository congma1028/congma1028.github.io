<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications by topics</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Cong Ma</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="paper.html">Papers</a></div>
<div class="menu-item"><a href="paper_topic.html" class="current">Papers&nbsp;by&nbsp;topics</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="tutorial.html">Tutorials</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications by topics</h1>
</div>
<h2>Transfer learning</h2>
<ul>
<li><p><a href="Publication/Lasso/lasso_suboptimality.pdf">On the Design-Dependent Suboptimality of the Lasso</a> <br />
R. Pathak, C. Ma <br />
<a href="https://github.com/reesepathak/lowerlassosim">[Code</a>]</p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Covariate-shift-MLE/CS-MLE.pdf">Maximum Likelihood Estimation is All You Need
for Well-Specified Covariate Shift</a> <br /> 
J. Ge, S. Tang, J. Fan, C. Ma, C. Jin <br />
to appear in <i>ICLR, 2024</i></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/CovariateShiftKernel/CovariateShift.pdf">Optimally Tackling Covariate Shift in RKHS-based Nonparametric Regression</a> <br />
C. Ma, R. Pathak, M. J. Wainwright <br />
<i>Annals of Statistics, 2023</i> <a href="Publication/CovariateShiftKernel/covariate-shift-slides.pdf">[Slides]</a> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/CovariateShiftNW/main.pdf">A New Similarity Measure for Covariate Shift with Applications to Nonparametric Regression</a> <br />
R. Pathak, C. Ma, M. J. Wainwright <br />
<i>ICML, 2022</i> (long presentation)</p>
</li>
</ul>
<h2>Reinforcement learning</h2>
<ul>
<li><p><a href="Publication/BatchedBandit/BatchedNB.pdf">Batched Nonparametric Contextual Bandits</a> <br />
R.&nbsp;Jiang, C. Ma <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/TD/TD_LFA.pdf">Sharp High-Probability Sample Complexities for Policy Evaluation with Linear Function Approximation</a> <br /> 
G. Li, W. Wu, Y. Chi, C. Ma, A. Rinaldo, Y. Wei <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/JSRL/jsrl.pdf">Jump-Start Reinforcement Learning</a> <br />
I. Uchendu, T. Xiao, Y. Lu, B. Zhu, M. Yan, J. Simon, M. Bennice, C. Fu, C. Ma, J. Jiao, S Levine, K Hausman <br />
<i>ICML, 2023</i></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/OFTRL/OFTRL.pdf"><img class="eq" src="eqs/940375977453228462-130.png" alt="O(1/T)" style="vertical-align: -5px" /> Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games</a> <br />
Y. Yang, C. Ma <br />
<i>ICLR, 2023</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/ContextualBandit/lcb_bounds_arxiv.pdf">Pessimism for Offline Linear Contextual Bandits using <img class="eq" src="eqs/9141172507192648814-130.png" alt="ell_{p}" style="vertical-align: -6px" /> Confidence Sets</a> <br />
G. Li, C. Ma, N. Srebro (alphabetical order) <br />
<i>NeurIPS, 2022</i>  <a href="Publication/ContextualBandit/lcb_bounds_poster.pdf">[Poster]</a> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/OPE/OPE.pdf">Minimax Off-Policy Evaluation for Multi-Armed Bandits</a> <br />
C. Ma, B. Zhu, J. Jiao, M. J. Wainwright <br />
<i>IEEE Transactions on Information Theory, 2022</i> <a href="Publication/OPE/OPE_slides.pdf">[Slides]</a> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/OfflineRL/OfflineRL.pdf">Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism</a> <br />
P. Rashidinejad, B. Zhu, C. Ma, J. Jiao, S. Russell <br />
<i>IEEE Transactions on Information Theory, 2022</i>  <br />
accepted in part to <i>NeurIPS 2021</i> <a href="Publication/OfflineRL/slides/PessimismRL.pdf">[Slides]</a> <br /></p>
</li>
</ul>
<h2>Scaled gradient descent</h2>
<ul>
<li><p><a href="Publication/Overparam/ScaledGD_Overparam.pdf">The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing</a> <br /> 
X. Xu, Y. Shen, Y. Chi, C. Ma <br />
<i>ICML, 2023</i> <a href="Publication/Overparam/ScaledGD_Overparam_Purdue.pdf">[Slides]</a><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/TPCA/TPCA.pdf">Fast and Provable Tensor Robust Principal Component Analysis via Scaled Gradient Descent</a> <br />
H. Dong, T. Tong, C. Ma, Y. Chi<br />
<i>Information and Inference: A Journal of the IMA, 2023</i> </p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Tensor/Tensor_ScaledGD.pdf">Scaling and Scalability: Provable Nonconvex Low-Rank Tensor Estimation from Incomplete Measurements</a> <br />
T. Tong, C. Ma, A. Prater-Bennette, E. Tripp, Y. Chi<br />
<i>Journal of Machine Learning Research, 2022</i><br />
accepted in part to <i>AISTATS, 2022</i></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/ScaledSM/ScaledNonsmooth.pdf">Low-Rank Matrix Recovery with Scaled Subgradient Methods: Fast and Robust Convergence Without the Condition Number</a> <br />
T. Tong, C. Ma, Y. Chi<br />
<i>IEEE Transactions on Signal Processing, 2021</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/ScaledGD/ScaledGD.pdf">Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent</a> <br />
T. Tong, C. Ma, Y. Chi<br />
<i>Journal of Machine Learning Research, 2021</i><br /></p>
</li>
</ul>
<h2>Ranking</h2>
<ul>
<li><p><a href="Publication/RankingSemiRandom/Semi_Random_Ranking.pdf">Top-<img class="eq" src="eqs/9600028874-130.png" alt="K" style="vertical-align: -0px" /> Ranking with a Monotone Adversary</a> <br />
Y.&nbsp;Yang, A.&nbsp;Chen, L.&nbsp;Orecchia, C. Ma <br />
<a href="Publication/RankingSemiRandom/topK_semi_random_slides.pdf">[Slides]</a><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Ranking/topK.pdf">Spectral Method and Regularized MLE Are Both Optimal for Top-<img class="eq" src="eqs/9600028874-130.png" alt="K" style="vertical-align: -0px" /> Ranking</a>  <br />
Y. Chen, J. Fan, C. Ma, K. Wang (alphabetical order)<br />
<i>Annals of Statistics, 2019</i>
<a href="Publication/Ranking/Slides/GroupMeeting/topK_group_meeting.pdf">[Slides]</a> </p>
</li>
</ul>
<h2>Low-rank matrix recovery</h2>
<ul>
<li><p><a href="Publication/CMC/cmc.pdf">Conformalized Matrix Completion</a> <br /> 
Y. Gui, R. F. Barber, C. Ma <br />
<i>NeurIPS, 2023</i> <a href="https://github.com/yugjerry/conf-mc">[Code]</a> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/SqrtMC/SqrtMC.pdf">Optimal Tuning-Free Convex Relaxation for Noisy Matrix Completion</a> <br />
Y. Yang, C. Ma <br />
<i>IEEE Transactions on Information Theory, 2023</i>  <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Spectral/SpectralMethods_FnTarticle-nowplain.pdf">Spectral Methods for Data Science: A Statistical Perspective</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma (alphabetical order)<br />
<i>Foundations and Trends&reg; in Machine Learning, 2021</i></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/RobustPCA/RPCA_noise.pdf">Bridging Convex and Nonconvex Optimization in Robust PCA: Noise, Outliers, and Missing Data</a> <br />
Y. Chen, J. Fan, C. Ma, Y. Yan (alphabetical order)<br />
<i>Annals of Statistics, 2021</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Mixture_LowRank/mixed-matrix-sensing.pdf">Learning Mixtures of Low-Rank Models</a> <br />
Y. Chen, C. Ma, H. V. Poor, Y. Chen<br />
<i>IEEE Transactions on Information Theory, 2021</i><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Implicit/paper.pdf">Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution</a> <br />
C. Ma, K. Wang, Y. Chi, Y. Chen <br />
<i>Foundations of Computational Mathematics, 2020</i> <br />
accepted in part to <i>ICML 2018</i> 
<a href="Publication/Implicit/Slides/implicit_reg_slides.pdf">[Slides]</a> </p>
</li>
</ul>
<ul>
<li><p><a href="Publication/MC_inference/MC_inference.pdf">Inference and Uncertainty Quantification for Noisy Matrix Completion</a> <br />
Y. Chen, J. Fan, C. Ma, Y. Yan (alphabetical order)<br />
<i>Proceedings of the National Academy of Sciences, 2019</i> 
<a href="Publication/MC_inference/Slides/Noisy_MC_inference_slides.pdf">[Slides]</a>  <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/NoisyMC/NoisyMC.pdf">Noisy Matrix Completion: Understanding Statistical Guarantees for Convex Relaxation via Nonconvex Optimization</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma, Y. Yan (alphabetical order)<br />
<i>SIAM Journal on Optimization, 2020</i> 
<a href="Publication/NoisyMC/Slides/NoisyMC_slides.pdf">[Slides]</a> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/BalancingFree/RectangularMF_TSP.pdf">Beyond Procrustes: Balancing-Free Gradient Descent for Asymmetric Low-Rank Matrix Sensing</a> <br />
C. Ma, Y. Li, Y. Chi <br />
<i>IEEE Transactions on Signal Processing, 2021</i> <br />
accepted in part to <i>Asilomar 2019</i></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/RandomInit/main.pdf">Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma (alphabetical order)<br />
<i>Mathematical Programming, 2019</i> 
<a href="Publication/RandomInit/Slides/random_init_slides.pdf">[Slides]</a>  </p>
</li>
</ul>
<ul>
<li><p><a href="Publication/RankOne/noncvx_covsketch_latest.pdf">Nonconvex Matrix Factorization from Rank-One Measurements</a><br />
Y. Li, C. Ma, Y. Chen, Y. Chi <br />
<i>IEEE Transactions on Information Theory, 2020</i> <br />
accepted in part to <i>AISTATS, 2019</i></p>
</li>
</ul>
<h2>Others</h2>
<ul>
<li><p><a href="Publication/SSL/ssl.pdf">Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage</a> <br /> 
Y. Gui, C. Ma, Y. Zhong <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/DL_survey/DL_survey.pdf">A Selective Overview of Deep Learning</a> <br />
J. Fan, C. Ma, Y. Zhong (alphabetical order)<br />
<i>Statistical Science, 2020</i> <br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/ISA/jasa.pdf">Inter-Subject Analysis: A Partial Gaussian Graphical Model Approach</a> <br />
C. Ma, J. Lu, H. Liu <br />
<i>Journal of the American Statistical Association, 2020</i> 
<a href="Publication/ISA/Slides/ISA.pdf">[Slides]</a><br /></p>
</li>
</ul>
<ul>
<li><p><a href="Publication/Panther/TOIS.pdf">Fast and Flexible Top-<img class="eq" src="eqs/9600028874-130.png" alt="K" style="vertical-align: -0px" /> Similarity Search on Large Networks</a> <br />
J. Zhang, J. Tang, C. Ma, H. Tong, Y. Jing, J. Li, W. Luyten, 	M. Moens <br />
<i>ACM Transactions on Information Systems, 2017</i> <br />
accepted in part to <i>KDD, 2015</i>  <br /> </p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-03-11 11:31:19 CDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
