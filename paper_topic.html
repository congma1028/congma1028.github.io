<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications by topics</title>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Cong Ma</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="paper.html">Papers</a></div>
<div class="menu-item"><a href="paper_topic.html">Papers&nbsp;by&nbsp;topics</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="tutorial.html">Tutorials</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications by topics</h1>
</div>
<h2>Reinforcement learning</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2510.15464" target="_blank" rel="noopener noreferrer">Learning to Answer from Correct Demonstrations</a> <br />
N. Joshi, G. Li, S. Bhandari, S. P. Kasiviswanathan, C. Ma, N. Srebro; <i>ICLR, 2026</i> <a href="Publication/Demonstrations/LearningToAnswerFromCorrectDemonstrations.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2511.03708" target="_blank" rel="noopener noreferrer">The Adaptivity Barrier in Batched Nonparametric Bandits: Sharp Characterization of the Price of Unknown Margin</a> <br />
R. Jiang, C. Ma; <a href="Publication/BatchedBandit/batch_nb_slides_uiuc.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.17732" target="_blank" rel="noopener noreferrer">Batched Nonparametric Contextual Bandits</a> <br />
R. Jiang, C. Ma; <i>IEEE Transactions on Information Theory, 2025</i> <a href="Publication/BatchedBandit/batch_nb_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2411.12786" target="_blank" rel="noopener noreferrer">Off-Policy Estimation with Adaptively Collected Data: The Power of Online Learning</a> <br />
J.&nbsp;Lee, C.&nbsp;Ma; <i>NeurIPS, 2024</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.19001" target="_blank" rel="noopener noreferrer">High-Probability Sample Complexities for Policy Evaluation with Linear Function Approximation</a> <br />
G. Li, W. Wu, Y. Chi, C. Ma, A. Rinaldo, Y. Wei; <i>IEEE Transactions on Information Theory, 2024</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2204.02372" target="_blank" rel="noopener noreferrer">Jump-Start Reinforcement Learning</a> <br />
I. Uchendu, T. Xiao, Y. Lu, B. Zhu, M. Yan, J. Simon, M. Bennice, C. Fu, C. Ma, J. Jiao, S. Levine, K. Hausman; <i>ICML, 2023</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2209.12430" target="_blank" rel="noopener noreferrer">\(O(1/T)\) Convergence of Optimistic-Follow-the-Regularized-Leader in Two-Player Zero-Sum Markov Games</a> <br />
Y. Yang, C. Ma; <i>ICLR, 2023</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2205.10671" target="_blank" rel="noopener noreferrer">Pessimism for Offline Linear Contextual Bandits using \(\ell_{p}\) Confidence Sets</a> <br />
G. Li, C. Ma, N. Srebro; <i>NeurIPS, 2022</i> <a href="Publication/ContextualBandit/lcb_bounds_poster.pdf" target="_blank" rel="noopener noreferrer">[Poster]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2101.07781" target="_blank" rel="noopener noreferrer">Minimax Off-Policy Evaluation for Multi-Armed Bandits</a> <br />
C. Ma, B. Zhu, J. Jiao, M. J. Wainwright; <i>IEEE Transactions on Information Theory, 2022</i> <a href="Publication/OPE/OPE_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2103.12021" target="_blank" rel="noopener noreferrer">Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism</a> <br />
P. Rashidinejad, B. Zhu, C. Ma, J. Jiao, S. Russell; <i>IEEE Transactions on Information Theory, 2022, accepted in part to NeurIPS, 2021</i> <a href="Publication/OfflineRL/slides/PessimismRL.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<h2>Transfer learning</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2411.15624" target="_blank" rel="noopener noreferrer">Trans-Glasso: A Transfer Learning Approach to Precision Matrix Estimation</a> <br />
B.&nbsp;Zhao, C.&nbsp;Ma, M.&nbsp;Kolar; <i>Journal of the American Statistical Association, 2025</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2407.06867" target="_blank" rel="noopener noreferrer">Distributionally Robust Risk Evaluation with an Isotonic Constraint</a> <br />
Y.&nbsp;Gui, R.&nbsp;F.&nbsp;Barber, C.&nbsp;Ma
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.00382" target="_blank" rel="noopener noreferrer">On the Design-Dependent Suboptimality of the Lasso</a> <br />
R. Pathak, C. Ma; <a href="https://github.com/reesepathak/lowerlassosim" target="_blank" rel="noopener noreferrer">[Code]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2311.15961" target="_blank" rel="noopener noreferrer">Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift</a> <br />
J. Ge, S. Tang, J. Fan, C. Ma, C. Jin; <i>ICLR, 2024</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2205.02986" target="_blank" rel="noopener noreferrer">Optimally Tackling Covariate Shift in RKHS-Based Nonparametric Regression</a> <br />
C. Ma, R. Pathak, M. J. Wainwright; <i>Annals of Statistics, 2023</i> <a href="Publication/CovariateShiftKernel/covariate-shift-slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2202.02837" target="_blank" rel="noopener noreferrer">A New Similarity Measure for Covariate Shift with Applications to Nonparametric Regression</a> <br />
R. Pathak, C. Ma, M. J. Wainwright (RP and CM contributed equally); <i>ICML, 2022 (long presentation)</i>
</p>
</li>
</ul>
<h2>Multi-modal learning</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2505.12473" target="_blank" rel="noopener noreferrer">Multi-Modal Contrastive Learning Adapts to Intrinsic Dimensions of Shared Latent Variables</a> <br />
Y. Gui, C. Ma, Z. Ma; <i>NeurIPS, 2025</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2509.21584" target="_blank" rel="noopener noreferrer">IndiSeek Learns Information-Guided Disentangled Representations</a> <br />
Y. Gui, C. Ma, Z. Ma
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2501.09336" target="_blank" rel="noopener noreferrer">Estimating Shared Subspace with AJIVE: The Power and Limitation of Multiple Data Matrices</a> <br />
Y.&nbsp;Yang, C. Ma; <a href="Publication/AJIVE/AJIVE.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2306.03335" target="_blank" rel="noopener noreferrer">Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage</a> <br />
Y. Gui, C. Ma, Y. Zhong
</p>
</li>
</ul>
<h2>Low-rank matrix recovery</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.10637" target="_blank" rel="noopener noreferrer">Conformalized Matrix Completion</a> <br />
Y. Gui, R. F. Barber, C. Ma; <i>NeurIPS, 2023</i> <a href="https://github.com/yugjerry/conf-mc" target="_blank" rel="noopener noreferrer">[Code]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2207.05802" target="_blank" rel="noopener noreferrer">Optimal Tuning-Free Convex Relaxation for Noisy Matrix Completion</a> <br />
Y. Yang, C. Ma; <i>IEEE Transactions on Information Theory, 2023</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2012.08496" target="_blank" rel="noopener noreferrer">Spectral Methods for Data Science: A Statistical Perspective</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma (alphabetical order); <i>Foundations and Trends&reg; in Machine Learning, 2021</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2001.05484" target="_blank" rel="noopener noreferrer">Bridging Convex and Nonconvex Optimization in Robust PCA: Noise, Outliers, and Missing Data</a> <br />
Y. Chen, J. Fan, C. Ma, Y. Yan (alphabetical order); <i>Annals of Statistics, 2021</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2009.11282" target="_blank" rel="noopener noreferrer">Learning Mixtures of Low-Rank Models</a> <br />
Y. Chen, C. Ma, H. V. Poor, Y. Chen; <i>IEEE Transactions on Information Theory, 2021</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1906.04159" target="_blank" rel="noopener noreferrer">Inference and Uncertainty Quantification for Noisy Matrix Completion</a> <br />
Y. Chen, J. Fan, C. Ma, Y. Yan (alphabetical order); <i>Proceedings of the National Academy of Sciences, 2019</i> <a href="Publication/MC_inference/Slides/Noisy_MC_inference_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1902.07698" target="_blank" rel="noopener noreferrer">Noisy Matrix Completion: Understanding Statistical Guarantees for Convex Relaxation via Nonconvex Optimization</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma, Y. Yan (alphabetical order); <i>SIAM Journal on Optimization, 2020</i> <a href="Publication/NoisyMC/Slides/NoisyMC_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2101.05113" target="_blank" rel="noopener noreferrer">Beyond Procrustes: Balancing-Free Gradient Descent for Asymmetric Low-Rank Matrix Sensing</a> <br />
C. Ma, Y. Li, Y. Chi; <i>IEEE Transactions on Signal Processing, 2021, accepted in part to Asilomar 2019</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1803.07726" target="_blank" rel="noopener noreferrer">Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval</a> <br />
Y. Chen, Y. Chi, J. Fan, C. Ma (alphabetical order); <i>Mathematical Programming, 2019</i> <a href="Publication/RandomInit/Slides/random_init_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1802.06286" target="_blank" rel="noopener noreferrer">Nonconvex Matrix Factorization from Rank-One Measurements</a> <br />
Y. Li, C. Ma, Y. Chen, Y. Chi; <i>IEEE Transactions on Information Theory, 2021, accepted in part to AISTATS, 2019</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1711.10467" target="_blank" rel="noopener noreferrer">Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution</a> <br />
C. Ma, K. Wang, Y. Chi, Y. Chen; <i>Foundations of Computational Mathematics, 2020, accepted in part to ICML, 2018</i> <a href="Publication/Implicit/Slides/implicit_reg_slides.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<h2>Scaled gradient descent</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2302.01186" target="_blank" rel="noopener noreferrer">The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing</a> <br />
X. Xu, Y. Shen, Y. Chi, C. Ma; <i>ICML, 2023</i> <a href="Publication/Overparam/ScaledGD_Overparam_Purdue.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2206.09109" target="_blank" rel="noopener noreferrer">Fast and Provable Tensor Robust Principal Component Analysis via Scaled Gradient Descent</a> <br />
H. Dong, T. Tong, C. Ma, Y. Chi; <i>Information and Inference: A Journal of the IMA, 2023</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2104.14526" target="_blank" rel="noopener noreferrer">Scaling and Scalability: Provable Nonconvex Low-Rank Tensor Estimation from Incomplete Measurements</a> <br />
T. Tong, C. Ma, A. Prater-Bennette, E. Tripp, Y. Chi; <i>Journal of Machine Learning Research, 2022, accepted in part to AISTATS, 2022</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2010.13364" target="_blank" rel="noopener noreferrer">Low-Rank Matrix Recovery with Scaled Subgradient Methods: Fast and Robust Convergence Without the Condition Number</a> <br />
T. Tong, C. Ma, Y. Chi; <i>IEEE Transactions on Signal Processing, 2021</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2005.08898" target="_blank" rel="noopener noreferrer">Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled Gradient Descent</a> <br />
T. Tong, C. Ma, Y. Chi; <i>Journal of Machine Learning Research, 2021</i>
</p>
</li>
</ul>
<h2>Ranking</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2406.13989" target="_blank" rel="noopener noreferrer">Random Pairing MLE for Estimation of Item Parameters in Rasch Model</a> <br />
Y. Yang, C. Ma; <i>Journal of the American Statistical Association, 2025</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.07445" target="_blank" rel="noopener noreferrer">Top-K Ranking with a Monotone Adversary</a> <br />
Y.&nbsp;Yang, A.&nbsp;Chen, L.&nbsp;Orecchia, C. Ma; <i>COLT, 2024</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1707.09971" target="_blank" rel="noopener noreferrer">Spectral Method and Regularized MLE Are Both Optimal for Top-K Ranking</a> <br />
Y. Chen, J. Fan, C. Ma, K. Wang (alphabetical order); <i>Annals of Statistics, 2019</i> <a href="Publication/Ranking/Slides/GroupMeeting/topK_group_meeting.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<h2>Others</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/1904.05526" target="_blank" rel="noopener noreferrer">A Selective Overview of Deep Learning</a> <br />
J. Fan, C. Ma, Y. Zhong (alphabetical order); <i>Statistical Science, 2020</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1709.07036" target="_blank" rel="noopener noreferrer">Inter-Subject Analysis: A Partial Gaussian Graphical Model Approach</a> <br />
C. Ma, J. Lu, H. Liu; <i>Journal of American Statistical Association, 2021</i> <a href="Publication/ISA/Slides/ISA.pdf" target="_blank" rel="noopener noreferrer">[Slides]</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1504.02577" target="_blank" rel="noopener noreferrer">Fast and Flexible Top-K Similarity Search on Large Networks</a> <br />
J. Zhang, J. Tang, C. Ma, H. Tong, Y. Jing, J. Li, W. Luyten, 	M. Moens; <i>ACM Transactions on Information Systems, 2017, accepted in part to KDD, 2015</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://muse.jhu.edu/article/799748" target="_blank" rel="noopener noreferrer">Modern Data Modeling: Cross-Fertilization of the Two Cultures</a> <br />
J. Fan, C. Ma, K. Wang, Z. Zhu (alphabetical order); <i>Observational Studies, 2021</i>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1837141" target="_blank" rel="noopener noreferrer">Comment on “A Tuning-Free Robust and Efficient Approach to High-Dimensional Regression”</a> <br />
J. Fan, C. Ma, K. Wang (alphabetical order); <i>Journal of the American Statistical Association, 2020</i>
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2026-02-12 18:02:59 CST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="_blank" rel="noopener noreferrer">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
