%\documentclass[letterpaper,draft]{beamer}
\documentclass[letterpaper,handout]{beamer}
%\documentclass[letterpaper]{beamer}

%---multiple pages on one sheet, ADD for handout--
%\usepackage{pgfpages}
%\pgfpagesuselayout{4 on 1}[letterpaper, landscape, border shrink=1mm]
%-------------------------------------------------
\usepackage{amsmath,amsfonts}
%\usepackage[misc]{ifsym} % for the dice symbol \Cube{}
%\usepackage{booktabs}
%\usepackage{mdwlist}
%\usepackage{amsfonts}
%\usetheme{Copenhagen}
%\usetheme{warsaw}
\setbeamertemplate{navigation symbols}{}
\usepackage[english]{babel}
\def\ul{\underline}
% or whatever

\usepackage[latin1]{inputenc}
\subject{Talks}

\def\Sum{\sum\nolimits}
\def\Prod{\prod\nolimits}
\def\P{\mathbb{P}}
\def\p{\mathrm P}
\def\E{\mathbb E}
\def\V{\mathrm{Var}}
\def\CV{\mathrm{Cov}}
\def\X{\mathcal{X}}
\def\F{\mathcal{F}}
\def\dt{\Delta}
\def\typo#1{\alert{#1}}
%-------------Answers------------
\def\Hide#1#2{\ul{~~~\onslide<#1>{\alert{#2}}~~~}}
\def\hide#1#2{\ul{~~\onslide<#1>{\alert{#2}}~~}}
%------Centered Page Number------
\input{Centerpgn}
\def\chapnum{27}
%--------------------------------
\setbeamertemplate{footline}[centered page number]

\title{STAT253/317 Winter 2013 Lecture \chapnum} \date{Mar 13, 2013} \author{Yibi Huang}
\begin{document}
% ----------------------------------------------------------------------
\begin{frame}\maketitle
\bigskip
\begin{center}\large
\begin{tabular}{ll}
$\bullet$ & It\^{o}'s Integral\\
$\bullet$ & It\^{o}'s Formula\\
\end{tabular}
\end{center}
\end{frame}
%% ----------------------------------------------------------------------
%\begin{frame}{Martingale}
%A \structure{\bf martingale} is a gambling term for a fair game in which the current information set $\F_t$ (the %formal term is called \structure{\em filtration}.)
%provides no advantage in predicting future winnings. A random variable $X_t$ with finite expectation
%is a martingale with respect to $\{\F_t\}$ if
%$$\E[X_{t}|\F_s]=X_s\quad\mbox{for all }s\le t.$$
%
%{\bf Remark}. Formally, the filtration $\{\F_t,\, t>0\}$ must have the following increasing property
%$$\F_s\subseteq \F_t\quad\mbox{for all }s\le t$$.
%\end{frame}
%% ----------------------------------------------------------------------
%\begin{frame}{Examples of Martingale}
%Let $B(t)$ be a standard Brownian Motion and the filtration $\F_t$ is $$\F_t=\mbox{information of $B(s)$ for }0\le %s\le t.$$
%Then the following processes are all Martingales
%\begin{itemize}
%\item $\{B(t),\; t\ge 0\}$
%\item $\{B^2(t)-t,\; t\ge 0\}$
%\item $\{e^{\theta B(t)-\theta^2 t/2},\; t\ge 0\}$
%\end{itemize}
%{\em Proof.} Given $B(u)$ for $0\le u\le s$, $B(t)=B(s)+(B(t)-B(s))$,
%in which $B(s)$ is known given $\F_s$, and $B(t)-B(s)$ is independent of $\F_s$ by the independent increment property %of the Brownian motion.
%\begin{align*}
%\E[B(t)|\F_s]&=\E[B(s)+B(t)-B(s)|B(u), 0\le u\le s]\\
%&=B(s)+\E[B(t)-B(s)|B(u), 0\le u\le s]\\
%&=B(s)
%\end{align*}
%This shows $\{B(t),\; t\ge 0\}$ is a martingale with respective to filtration $\{\F_t,t\ge 0\}$.
%\end{frame}
%% ----------------------------------------------------------------------
%\begin{frame}
%\begin{align*}
%&\E[B^2(t)-t|\F_s]\\
%={}&\E\{[\alert{B(s)}+B(t)-\alert{B(s)}]^2|\F_s\}-t\\
%={}&\E\{B^2(s)+2B(s)[B(t)-B(s)]+[B(t)-B(s)]^2|\F_s\}-t\\
%={}&B^2(s)+2B(s)\underbrace{\E[B(t)-B(s)|F_t]}_{=0}+\underbrace{\E\{[B(t)-B(s)]^2|\F_s\}}_{=t-s}-t\\
%={}&B^2(s)-s
%\end{align*}
%This shows $\{B^2(t)-t,\; t\ge 0\}$ is a martingale with respective to filtration $\{\F_t,t\ge 0\}$.
%\begin{align*}
%\E[e^{\theta B(t)-\theta^2 t/2}|\F_s]
%&=e^{\theta \alert{B(s)}-\theta^2 t/2}\E\{e^{\theta (B(t)-\alert{B(s)})}|\F_s\}\\
%&=e^{\theta B(s)-\theta^2 t/2}\E\{e^{\theta (B(t)-B(s))}\}\\
%&=e^{\theta B(s)-\theta^2 t/2}e^{\theta^2 (t-s)/2}\\
%&=e^{\theta B(s)-\theta^2 s/2}
%\end{align*}
%This shows $\{e^{\theta B(t)-\theta^2 t/2},\; t\ge 0\}$ is a martingale with respective to filtration $\{\F_t,t\ge %0\}$ for all $\theta$.
%\end{frame}
%% ----------------------------------------------------------------------
%\begin{frame}
%If $\{X(t)\}$ is a Martingale, a consequence is that $$\E[X(t)]=\E[X(0)]\quad\mbox{ for all }t$$ since
%$\E[X(t)|\F_0]=X(0)$ and by the tower property of conditional expectation,
%$$\E[X(t)]=\E[\E[X(t)|\F_0]]=\E[X(0)].$$\bigskip
%
%
%\end{frame}
%% ----------------------------------------------------------------------
\begin{frame}{Adapted Processes}
Let $\{B(t),t\ge0\}$ be the standard Brownian motion process.\par\medskip

We say a stochastic process $\{X(t),t\ge 0\}$ is \structure{\em adapted} to $\{B(t),t\ge 0\}$
if for each $t$, $X(t)$ is known given $\{B(u),0\le u\le t\}$,
and $X(t)$ does not depend on what occurs in the future $\{B(u), u> t\}$.\bigskip

{\bf Example.} The following $X(t)$'s are all adapted to $\{B(t),t\ge 0\}$.
\begin{itemize}
\item $X(t)=f(t,B(t))$, where $f(t,x)$ is a non-random function
\item $X(t)=\max_{0\le s\le u}B(u)$
\item $X(t)=B(t+a)$, if $a<0$
\end{itemize}
However, if $a>0$, $X(t)=B(t+a)$ is NOT adapted to $\{B(t),t\ge 0\}$ since $X(t)$ depends on the future $B(t+a).$
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{It\^{o} Integral}
Let $B(t)$ be a standard Brownian Motion and $X(t)$ be a process adapted to $\{B(t),t\ge 0\}$ with the property that
$$\E\left[\int_0^T X^2(t)dt\right]\le \infty\quad\mbox{for some }T$$
For $0\le a<b\le T$, the integral $\int_a^b X(t)d B(t)$ is defined as
$$\int_a^b X(t)d B(t)=\lim_{\|\Pi\|\to 0}\sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]$$
where $\|\Pi\|$ is the mesh size $\displaystyle\max_{0\le j\le n-1}|t_{j+1}-t_j|$ of the partition $$\Pi =\{a=t_0<t_1<\ldots<t_n=b\}.$$
We omit the proof to show that the integral is well-defined.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Properties of the It\^{o} Integral}
Let $X(t)$ be a process adapted to the filtration $\{\F_t,t\ge 0\}$ with
$$\E\left[\int_0^T X^2(t)dt\right]\le \infty.$$
For $0\le t\le T$, the process
$$I(t)=\int_0^t X(u)d B(u)$$
defined as in the previous page has the following properties
\begin{itemize}
\item {\bf Continuity}: As a function of $t$, the paths of $I(t)$ are continuous
\item {\bf Adaptivity}: $\{I(t),t\ge 0\}$ is adapted to $\{B(t),t\ge 0\}$
\item {\bf Linearity}: If $\{X(t)\}$ and $\{Y(t)\}$ are both adapted to $\{B(t),t\ge 0\}$,
then for all constants $a$ and $b$
$$\int_0^t aX(u)+bY(t)d B(u)=a\int_0^t X(u)d B(u)+b\int_0^t Y(u)d B(u)$$
\end{itemize}
{\em Proof.} Omitted
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Mean of It\^{o} Integral}
Let $I(t)=\int_0^t X(u)d B(u)$. Then $\E[I(t)]=0.$\bigskip

{\em Proof.}

We omit the justification of the interchangeability of taking limit and expectation.
Since $\{X(t)\}$ is adapted to $\{B(t)\}$, $X(t_j)$ is independent of $B(t_{j+1})-B(t_j)$.
\begin{align*}
\E[I(t)]&=\lim_{\|\Pi\|\to 0}\E\Big[\Sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]\Big]\\
&=\lim_{\|\Pi\|\to 0}\sum_{j=0}^{n-1}\E[X(t_j)]\underbrace{\E[B(t_{j+1})-B(t_j)]}_{=0}\\
&=0
\end{align*}
{\bf Remark.} This is not true for Stratonovich integral. For example, in Stratonovich sense,
$$\E\left[\int_0^t B(u) dB(u)\right]=\frac{1}{2}\E[B^2(t)]=\frac{t}{2}>0.$$
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Variance of It\^{o} Integral}
Let $I(t)=\int_0^t X(u)d B(u)$. Then $\V(I(t))=\int_0^t \E[X^2(u)]du$.

{\em Proof.}
From that $\E[\sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]]=0$, we know
\begin{align*}
&\V\left(\Sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]\right)\\[-3pt]
&=\E\left\{\Sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]\right\}^2=I+II
\end{align*}
where
\begin{align*}
I&=\Sum_{j=0}^{n-1}\E\{X^2(t_j)[B(t_{j+1})-B(t_j)]^2\}\\[-3pt]
II&=\Sum_{0\le i<j\le n-1}2\E\{X(t_i)X(t_j)[B(t_{i+1})-B(t_i)][B(t_{j+1})-B(t_j)]\}
\end{align*}
Since $\{X(t)\}$ is adapted to $\{B(t)\}$, $X(t_j)$ is independent of $B(t_{j+1})-B(t_j)$, we have
\begin{align*}
I&=\sum_{j=0}^{n-1}\E[X^2(t_j)]\E[B(t_{j+1})-B(t_j)]^2=\sum_{j=0}^{n-1}\E[X^2(t_j)](t_{j+1}-t_j)
\end{align*}
which approaches $\int_0^t\E[X^2(u)]du$ as $\|\Pi\|\to 0$.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Variance of It\^{o} Integral (Cont'd)}
For $II$, as $\{X(t)\}$ is adapted, for $t_i<t_j$,
$X(t_j)$, $X(t_i)$, and $B(t_{i+1})-B(t_i)$ depend only on those happen by time $t_j$, and hence are independent of
$B(t_{j+1})-B(t_j)$. Thus we have
\begin{align*}
&\E\{X(t_j)X(t_i)[B(t_{i+1})-B(t_i)][B(t_{j+1})-B(t_j)]\}\\
={}&\E\{X(t_j)X(t_i)[B(t_{i+1})-B(t_i)]\}\underbrace{\E[B(t_{j+1})-B(t_j)]}_{=0}=0
\end{align*}
As all the terms in $II$ are 0, we know $II = 0.$
We can see that
\begin{align*}
\V(I(t))=\E[I^2(t)]&=\lim_{\|\Pi\|\to 0}\E\left\{\Sum_{j=0}^{n-1}X(t_j)[B(t_{j+1})-B(t_j)]\right\}^2\\
&=\lim_{\|\Pi\|\to 0}I+II=\int_0^t\E[X^2(u)]du.
\end{align*}
Again we omit the justification of the interchangeability of taking limit and expectation.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Quadratic Variation of It\^{o} Integral}
Let $I(t)=\int_0^t X(u)d B(u)$. The quadratic variation of $I(t)$ up to time $t$ is $$[I,I](t)=\int_0^t X^2(u)du.$$
{\em Informal Proof.}
\begin{align*}
\Sum_{j=0}^{n-1}[I(t_{j+1})-I(t_j)]^2
&=\Sum_{j=0}^{n-1}\left(\int_{t_j}^{t_{j+1}} X(u)d B(u)\right)^2\\
&\approx\Sum_{j=0}^{n-1} X^2(t_j)[B(t_{j+1})-B(t_j)]^2\\
&\approx\Sum_{j=0}^{n-1} X^2(t_j)(t_{j+1}-t_j)
\end{align*}
As $\|\Pi\|\to 0$, the quantity on the left hand side approaches the quadratic variation of $I(t)$ up to time $t$, $[I,I](t)$, and the last quantity on the right hand side approaches $\int_0^t X^2(u)du.$\bigskip

{\bf Remark. } The two approximations above all need rigorous justifications.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{It\^{o}'s Formula}
Let $u(x,t)$ be a function of $x\in \mathbb{R}$ and $t \ge 0$ that is twice continuously differentiable
in $x$ and once continuously differentiable in $t$, and let $\{B(t)\}$ be a Brownian motion process.
Denote by $u_t$, $u_x$, and $u_{xx}$ the first and second partial derivatives of $u$ with respect to the variables
$t$ and $x$. Then
\begin{align*}
u(B(t),t) - u(0,0)
&=\int_0^t u_x(B(s),s)d B(s)\\[-3pt]
&\quad+
\int_0^t u_t(B(s),s)d s +\frac{1}{2}\int_0^tu_{xx}(B(s),s)d s.
\end{align*}

{\bf Example 1.}
Let $u(t,x)=x^2/2$, then $u_t=0$, $u_x=x$, $u_{xx}=1$. By It\^{o}'s Formula, we have
$$
\frac{1}{2}B^2(t)-\frac{1}{2}\underbrace{B^2(0)}_{=0}
=\int_0^t B(s)d B(s) + \frac{1}{2}\underbrace{\int_0^t1d s}_{=t}
$$
consistent with the result we got in Lecture 26, that
\centerline{$\int_0^t B(s)d B(s)=[B^2(t)-t]/2.$}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Example 2}
Let $u(x,t)=f(t)x$, where $f(t)$ is a differentiable function.
Then $u_t=f'(t)x$, $u_x=f(t)$, $u_{xx}=0.$ By It\^{o}'s Formula, we have
$$f(t)B(t) - f(0)B(0)=\int_0^t f(s)d B(s)+\int_0^t f'(s)B(s)d s$$
Then we get the ``integration-by-part formula'' for non-random integrant
$$\int_0^t f(s)d B(s) = f(t)B(t) - f(0)B(0)-\int_0^t f'(s)B(s)d s.$$
It is not hard to show that when $X(t)=f(t)$ is non-random, the It\^{o} integral
$$I(t)=\int_0^t X(u)d B(u), \quad t\ge 0$$
is also a Gaussian process. However, when $X(t)$ is random, $\{I(t)\}$ is usually no longer Gaussian.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Example 3. Stock Price Model}
First consider a discrete-time model that $S_n$ is the price of a certain stock at period $n$.
Assume that the return in one period is a constant $\mu$ plus a noise $\epsilon$, that is
$$\frac{S_{n+1}-S_n}{S_n}=\mu+\epsilon_{n+1}.$$
The noise terms $\epsilon_{i}$'s are usually assume to be i.i.d. with mean 0 and variance $\sigma^2.$
As we shrink the length of one time period, the mean return $\mu$ should be shrinked proportionally,
and the variability of the noise should be decreased, too.

For these reason, in continuous-time, stock price is often modeled as
\begin{equation}
\frac{S(t+\Delta t)-S(t)}{S(t)}=\mu \Delta t +\sigma \underbrace{[B(t+\Delta t)-B(t)]}_{\sim N(0,\Delta t)}\label{eq1}
\end{equation}
or is written as
\begin{equation}
\frac{dS(t)}{S(t)}=\mu d t +\sigma dB(t).\label{eq2}
\end{equation}

\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Example 3. Stock Price Model}
The formal meaning of equation \eqref{eq2} is the integral equation,
$$S(t)-S(0)=\int_0^t \mu S(t)d t+ \int_0^t\sigma S(t) dB(t).$$
From the expression \eqref{eq1} above, we can see that the last term $\int_0^t\sigma S(t) dB(t)$ is an It\^{o} integral rather than a Stratonovich integral.

Now we will use It\^{o}'s formula to find a solution to the integral equation above.
Let $u(x,t) = \exp(ax + bt)$, then $u_t=b u(x,t)$, $u_x=a u(x,t)$, $u_{xx}=a^2u(x,t).$ By It\^{o}'s Formula, we have
$$
u(B(s),s) - 1=\int_0^t a\, u(B(s),s)d B(s)+\int_0^t (b+\frac{a^2}{2}) u(B(s),s)d s.
$$
We can see that if let $a=\sigma$, $b=\mu-\sigma^2/2$, then
$$S(t)=u(B(s),s)=\exp(\sigma B(t)+ (\mu-\sigma^2/2)t)$$
is a solution to the integral equation above.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Sketch of Proof of It\^{o}'s Formula}
Let $\Pi =\{0=t_0<t_1<\ldots<t_n=t\}$ be a {\em partition} of $[0,t]$.
Taking a Taylor expansion of $u(x,t)$ with respect to the point $(B(t_j),t_j)$,
we have
\begin{align*}
u(x,t)-u(B(t_j),t_j)&=u_x(B(t_j),t_j)(x-B(t_j))\\
&\quad+u_t(B(t_j),t_j)(t-t_j)\\
&\quad+\frac{1}{2}u_{xx}(B(t_j),t_j)(x-B(t_j))^2\\
&\quad+u_{tx}(B(t_j),t_j)[x-B(t_j)](t-t_j)\\
&\quad+\frac{1}{2}u_{tt}(B(t_j),t_j)(t-t_j)^2\\
&\quad+\,\mbox{higher-order terms}
\end{align*}
Thus,
\begin{align*}
u(B(t),t)-u(B(0),0)&=\Sum_{j=0}^{n-1}u(B(t_{j+1}),t_{j+1})-u(B(t_j),t_j)\\
&=I+II+III+IV+V
\end{align*}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}
where
\begin{align*}
I&=\Sum_{j=0}^{n-1}u_x(B(t_j),t_j)(B(t_{j+1})-B(t_j))\longrightarrow \int_0^t u_x(B(t),t)dB(t)\\
II&=\Sum_{j=0}^{n-1}u_t(B(t_j),t_j)(t_{j+1}-t_j)\qquad\qquad\;\longrightarrow \int_0^t u_t(B(t),t)dt\\
III&=\frac{1}{2}\Sum_{j=0}^{n-1}u_{xx}(B(t_j),t_j)(B(t_{j+1})-B(t_j))^2\\
   &\approx\frac{1}{2}\Sum_{j=0}^{n-1}u_{xx}(B(t_j),t_j)(t_{j+1}-t_j)\quad\;\;\longrightarrow \int_0^t u_{xx}(B(t),t)dt\\
IV&=\Sum_{j=0}^{n-1}u_{tx}(B(t_j),t_j)[B(t_{j+1})\!-\!B(t_j)](t_{j+1}\!-\!t_j)\longrightarrow 0\\
V&=\frac{1}{2}\Sum_{j=0}^{n-1}u_{tt}(B(t_j),t_j)(t_{j+1}-t_j)^2\qquad\qquad\quad\;\longrightarrow 0
\end{align*}
as $\|\Pi\|\to 0$.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}
The limit of $I$ and $II$ are straightforward from the definition of It\^{o}'s integral and Riemann integral.

The approximation of $III$ must be done by showing
$$\Sum_{j=0}^{n-1}u_{xx}(B(t_j),t_j)[(B(t_{j+1})-B(t_j))^2-(t_{j+1}-t_j)]\to 0$$
as $\|\Pi\|\to 0$.
\end{frame}
% ----------------------------------------------------------------------
\end{document}
\begin{frame}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}
\end{frame}
% ----------------------------------------------------------------------
