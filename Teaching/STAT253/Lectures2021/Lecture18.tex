%\documentclass[letterpaper,draft]{beamer}
\documentclass[letterpaper,handout, mathserif]{beamer}
%\documentclass[letterpaper]{beamer}

%---multiple pages on one sheet, ADD for handout--
%\usepackage{pgfpages}
%\pgfpagesuselayout{4 on 1}[letterpaper, landscape, border shrink=1mm]
%-------------------------------------------------
\usepackage{amsmath,amsfonts}
%\usepackage[misc]{ifsym} % for the dice symbol \Cube{}
%\usepackage{booktabs}
%\usepackage{mdwlist}
\usepackage{amsfonts}
%\usetheme{Copenhagen}
%\usetheme{warsaw}
\setbeamertemplate{navigation symbols}{}
\usepackage[english]{babel}
\def\ul{\underline}
% or whatever

\usepackage[latin1]{inputenc}
\subject{Talks}

\def\Sum{\sum\nolimits}
\def\Prod{\prod\nolimits}
\def\p{\mathrm P}
\def\E{\mathbb E}
\def\V{\mathrm Var}
\def\CV{\mathrm Cov}
\def\X{\mathcal{X}}
\def\dt{\Delta}
\def\typo#1{\alert{#1}}
%-------------Answers------------
\def\Hide#1#2{\ul{~~~\onslide<#1>{\alert{#2}}~~~}}
\def\hide#1#2{\ul{~~\onslide<#1>{\alert{#2}}~~}}
\def\hid#1#2{\onslide<#1>{\alert{#2}}}
%------Centered Page Number------
\input{Centerpgn}
\def\chapnum{18}
%--------------------------------
\setbeamertemplate{footline}[centered page number]

\title{STAT253/317 Lecture \chapnum}\date{} \author{Cong Ma}
\begin{document}
% ----------------------------------------------------------------------
\begin{frame}
\maketitle
\begin{center}\large
\begin{tabular}{ll}
Section 7.7 & The Inspection Paradox\\
Chapter 8   & Queueing Models
\end{tabular}
\end{center}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Section 7.7 The Inspection Paradox}
Given a renewal process $\{N(t),t\ge 0\}$ with interarrival times
$\{X_i, i\ge 1\}$, the length of the current cycle, $$X_{N(t)+1}=S_{N(t)+1}-S_{N(t)}$$
tend to be \structure{\em longer} than $X_i$, the length of an ordinary cycle. \bigskip

Precisely speaking, $X_{N(t)+1}$ is \structure{stochastically greater than} $X_i$, which means
$$\p(X_{N(t)+1}>x)\ge \p(X_{i}>x), \quad\mbox{for all }x\ge 0.$$
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Heuristic Explanation of the Inspection Paradox}
Suppose we pick a time $t$ uniformly in the range $[0,T]$, and then select the cycle that contains $t$.
\begin{itemize}
\item Possible cycles that can be selected: $X_1, X_2,\ldots,X_{N(T)+1}$
\item These cycles are not equally likely to be selected.\\
The longer the cycle, the greater the chance.
$$
\p(\mbox{$X_i$ is selected})= X_i/T,\quad \mbox{for }1\le i\le N(T)
%(T-S_{N(T)})/T & \mbox{if }i = X_{N(T)+1}
$$
\item So the expected length of the selected cycle $X_{N(t)+1}$ is roughly
$$
\sum_{i=1}^{N(T)}X_i\times \frac{X_i}{T}
=\frac{\sum_{i=1}^{N(T)}X_i^2}{T}\to\frac{\E[X_i^2]}{\E[X_i]}\ge \E[X_i]\quad\mbox{as }T\to\infty.
$$
\item Last time we have shown that if $F$ is non-lattice,
$$\lim_{t\to\infty}\E[Y(t)]=\lim_{t\to\infty}\E[A(t)]=\frac{\E[X_i^2]}{2\E[X_i]},$$
Since $X_{N(t)+1}=A(t)+Y(t)$,  $\lim_{t\to\infty}\E[X_{N(t)+1}]=\dfrac{\E[X_i^2]}{\E[X_i]}$
\end{itemize}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Example: Waiting Time for Buses}
\begin{itemize}
\item Passengers arrive at a bus station at Poisson rate $\lambda$
\item Buses arrive one after another according to a renewal process with interarrival times $X_i$, $i\ge 1$,
independent of the arrival of customers.
\item If $X_i$ is deterministic, always equals 10 mins, then on average passengers has to wait 5 mins
\item If $X_i$ is random with mean 10 min, then a passenger arrives at time $t$ has to wait $Y(t)$ minutes. Here $Y(t)$ is the residual life of the bus arrival process.
We know that
$$
\E[Y(t)]\to\frac{\E[X_i^2]}{2\E[X_i]}\ge \frac{\E[X_i]}{2}=\mbox{5 min}.
$$
Passengers on average have to weight more than half the mean length of interarrival times of buses.
\end{itemize}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Class Size in U of Chicago}

University of Chicago is known for its small class size,
but a majority of students feel most classes they enroll are big.\\

Suppose U of Chicago have five classes of size
\[
10, 10, 10, 10, 100
\]
respectively.
\begin{itemize}
\item Mean size of the 5 classes: $(10+10+10+10+100)/5=28.$
\item From students' point of view, only the 40 students in the first four classes feel they are in a small class, the 100 students in the big class feel they are in a large class.

Average class size students feel
\[
\frac{\overbrace{10+\cdots+10}^{40\text{ students}}+\overbrace{100+\ldots+100}^{100\text{ students}}}{140}
=\frac{10\times40+100\times100}{140}\approx74.3.
\]
\end{itemize}

\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Proof of the Inspection Paradox}
%$$\p(X_{N(t)+1}>x)\ge \p(X_{i}>x), \quad\mbox{for all }x\ge 0.$$

% {\em Proof.}
For $s>x$,
$$\p(X_{N(t)+1}>x|S_{N(t)}=t-s) = 1\ge \p(X_{i}>x)$$
For $s<x$,
\begin{align*}
&\p(X_{N(t)+1}>x|S_{N(t)}=t-s)\\
%={}&\p(X_{i+1}>x|S_{i}=t-s)\\
={}&\p(X_{1}>x|X_{1}> s)\\
={}&\frac{\p(X_{1}>x,\,X_{1}> s)}{\p(X_{1}> s)}\\
={}&\frac{\p(X_{1}>x)}{\p(X_{1}> s)}\\
\ge{}&\p(X_{1}>x)
\end{align*}
Thus $\p(X_{N(t)+1}>x|S_{N(t)}=t-s)\ge \p(X_{i}>x)$ for all $N(t)$ and $S_{N(t)}$.
The claim is validated
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Limiting Distribution of $X_{N(t)+1}$}
If the distribution $F$ of the interarrival times is non-lattice,
we can use an alternating renewal process argument to determine
$$G(x)=\lim_{t\to\infty}\p(X_{N(t)+1}\le x).$$
We say the renewal process is ON at time $t$ iff $X_{N(t)+1}\le x$, and OFF otherwise.
Thus in the $i$th cycle,
$$\mbox{the length of ON time is}
\begin{cases}
X_i & \mbox{if }X_i\le x,\mbox{ and}\\
0 &\mbox{otherwise}
\end{cases}
$$
and hence
\begin{align*}
G(x)=\lim_{t\to\infty}\p(X_{N(t)+1}\le x)&=\frac{\E[\mbox{On time in a cycle}]}{\E[\mbox{cycle time}]}\\
&=\frac{\E[X_i\mathbf{1}_{\{X_i\le x\}}]}{\E[X_i]}=\frac{\int_{0}^{x} z f(z)dz}{\mu}
\end{align*}
%In fact $G(x)=-\frac{x(1-F(x))}{\mu}+F_e(x) < F_e(x).$
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Chapter 8\; Queueing Models}
A queueing model consists ``customers'' arriving to receive some service and then depart. The mechanisms involved are
\begin{itemize}
\item input mechanism: the arrival pattern of customers in time
\item queueing mechanism: the number of servers, order of the service
\item service mechanism: the time to serve one or a batch of customers
\end{itemize}
We consider queueing models that follow the most common rule of service: first come, first served.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Common Queueing Processes}
It is often reasonable to assume
\begin{itemize}
\item the interarrival times of customers are i.i.d. (the arrival of customers follows a renewal process),
\item the service times for customers are i.i.d. and are independent of the arrival of customers.
\end{itemize}

Notation: $M=$ memoryless, or Markov, $G=$ General
\begin{itemize}
\item $M/M/1$: Poisson arrival, service time $\sim Exp(\mu)$, 1 server\\
= a birth and death process with birth rates $\lambda_j\equiv \lambda$, and death rates $\mu_j\equiv \mu$
\item $M/M/\infty$: Poisson arrival, service time $\sim Exp(\mu)$, $\infty$ servers\\
= a birth and death process with birth rates $\lambda_j\equiv \lambda$, and death rates $\mu_j\equiv j\mu$
\item $M/M/k$: Poisson arrival, service time $\sim Exp(\mu)$, $k$ servers\\
= a birth and death process with birth rates $\lambda_j\equiv \lambda$, and death rates $\mu_j\equiv \min(j,k)\mu$
\end{itemize}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Common Queueing Processes (Cont'd)}
\begin{itemize}
\item $M/G/1$: Poisson arrival, General service time $\sim G$, 1 server
\item $M/G/\infty$: Poisson arrival, General service time $\sim G$, $\infty$ server
\item $M/G/k$: Poisson arrival, General service time $\sim G$, $k$ server
\item $G/M/1$: General interarrival time, service time $\sim Exp(\mu)$, 1 server
\item $G/G/k$: General interarrival time $\sim F$, General service time $\sim G$, $k$ servers
\item $\ldots$
\end{itemize}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Quantities of Interest for Queueing Models}
Let
\begin{align*}
X(t) &= \mbox{number of customers in the system at time }t\\
Q(t) &= \mbox{number of customers waitng in queue at time }t
\end{align*}
Assume that $\{X(t), t \ge 0\}$ and $\{Q(t), t \ge 0\}$ has a stationary distribution.
\begin{itemize}
\item $L=$ the average number of customers in the system
$$L=\lim_{t\to\infty}\frac{\int_0^t X(t)dt}{t};$$
\item $L_Q=$ the average number of customers waiting in queue (not being served);
$$L_Q=\lim_{t\to\infty}\frac{\int_0^t Q(t)dt}{t};$$
\item $W=$ the average amount of time, including the time waiting in queue and service time, a customer spends in the system;
\item $W_Q=$ the average amount of time a customer spends waiting in queue (not being served).
\end{itemize}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Little's Formula}
Let
$$N(t) = \mbox{number of customers enter the system at or before time }t.$$
We define $\lambda_a$ be the arrival rate of entering customers,
$$
\lambda_a=\lim_{t\to\infty}\frac{N(t)}{t}
$$
\textbf{Little's Formula:}
\begin{align*}
L &=\lambda_a W\\
L_Q &=\lambda_a W_Q
\end{align*}
\end{frame}
\end{document}
% ----------------------------------------------------------------------
\begin{frame}{Cost Identity}
Many of interesting and useful relationships between quantities in Queueing models can be obtained by using the \structure{\em cost identity}.

Imagine that entering customers are forced to pay money (according to some
rule) to the system. We would then have the following basic cost identity:
\begin{align*}
&\mbox{average rate at which the system earns}\\
&= \lambda_a\times \mbox{average amount an entering customer pays}
\end{align*}
{\em Proof.} Let $R(t)$ be the amount of money the system has earned by time $t$. Then we have
\begin{align*}
&\mbox{average rate at which the system earns}\\
&=\lim_{t\to\infty}\frac{R(t)}{t}=\lim_{t\to\infty}\frac{N(t)}{t}\frac{R(t)}{N(t)}
=\lambda_a\lim_{t\to\infty}\frac{R(t)}{N(t)}\\
&=\lambda_a\times \mbox{average amount an entering customer pays},
\end{align*}
provided that the limits exist.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Proof of Little's Formula}
To prove $L=\lambda_a W$:
\begin{itemize}
\item we use the payment rule:
$$\mbox{each customer pays \$1 per unit time while in the system}.$$
\item the average amount customers pay = $W$, the average waiting time of customers.
\item the amount of money the system earns during the time interval $(t,t+\dt t)$ is $X(t)\dt t$, where $X(t)$ is the number of customers in the system at time $t$ ,
\item and the rate the system earns is thus $$\frac{\lim_{t\to\infty}\int_0^{t}X(s)ds}{t}=L,$$
the formula follows from the cost identity.
\end{itemize}
To prove $L_Q=\lambda_a W_Q$, we use the payment rule:
$$\mbox{each customer pays \$1 per unit time while in queue}.$$
The argument is similar.
\end{frame}
% ----------------------------------------------------------------------
\end{document}
\begin{frame}{}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{7.5\; Regenerative Processes}
A \structure{\bf regenerative process} a stochastic process $\{X(t), t \ge 0\}$ having
the property that there exist time points $T_1$ at which the process (probabilistically)
restarts itself. That is
$$
\{X(t+T_1), t \ge 0\}\sim\{X(t), t \ge 0\}
$$
Note that this property implies the existence of further times $T_2$, $T_3,\ldots$, having the same property as $T_1$, and it follows that $T_1$, $T_2,\ldots$, constitute the arrival times of a renewal process.\bigskip

{\bf Example}. A recurrent Markov chain is regenerative, and $T_1$ represents the time of the first
transition into the initial state.
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Markov Chain and Renewal Process}
Given a Markov chain $\{X_n, n\ge 0\}$, $X_0=i$. Let
\begin{align*}
N_i(t)&=\Sum_{0\le n\le t}\mathbf{1}_{\{X_n=i\}}\\
&=\mbox{number of times the chain visits state $i$ by time $t$}
\end{align*}
Note that $\{N_i(t), t\ge 0\}$ is a renewal process
where the interarrival times $T(i)$ are the number of steps between consecutive visits to state $i$.\bigskip

In either cases, we have the Elementary Renewal Theorem (Thm 7.1)
$$
\lim_{t\to\infty}\frac{m_i(t)}{t}=\frac{1}{\E(T(i))}
$$
where $m_i(t)=\E[N(t)]=\Sum_{0\le n\le t}P(X_n=i)=\Sum_{0\le n\le t}P^{(n)}_{ii}$
\end{frame}
% ----------------------------------------------------------------------
\begin{frame}{Markov Chain and Renewal Process (Cont'd)}
At every cycle, the renewal process is ON for one unit of time after every visits to state $i$.
So length of ON time in a cycle is fixed at $1$.
By Proposition 7.4, it follows that
$$
\mbox{the long-run proportion of time in state }i=\frac{1}{\E[\mbox{cycle time}]}=\frac{1}{\E[T_i]}
$$
\end{frame}
% ----------------------------------------------------------------------
