<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>STAT 280: Optimization </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Cong Ma</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>STAT 280: Optimization  <br /></h1>
<div id="subtitle"><a href="https://congma1028.github.io/index.html" target=&ldquo;blank&rdquo;>Cong Ma</a>, University of Chicago, Winter 2025
</div>
</div>
<ul>
<li><p><b></b>Lec 1 (Jan 7):<b></b> Introduction to optimization and several types of functions
</p>
</li>
<li><p><b></b>Lec 2 (Jan 9):<b></b> Univariate optimization: optimality conditions and Newton's method
</p>
</li>
<li><p><b></b>Lec 3 (Jan 14):<b></b> Analysis of Newton’s method
</p>
</li>
<li><p><b></b>Lec 4 (Jan 16):<b></b> Linear algebra and convergence in metric space
</p>
</li>
<li><p><b></b>Lec 5 (Jan 21):<b></b> Continuous functions and coercive functions
</p>
</li>
<li><p><b></b>Lec 6 (Jan 23):<b></b> Derivative, gradient and Jacobian
</p>
</li>
<li><p><b></b>Lec 7 (Jan 28):<b></b> No lecture today
</p>
</li>
<li><p><b></b>Lec 8 (Jan 30):<b></b> More examples; PSD matrices, matrix-variate functions
</p>
</li>
<li><p><b></b>Lec 9 (Feb 4):<b></b> Log-determinant function and Hessian, multi-variate Taylor’s theorem
</p>
</li>
<li><p><b></b>Lec 10 (Feb 6):<b></b> Convex sets and functions
</p>
</li>
<li><p><b></b>Lec 11 (Feb 11):<b></b> Necessary and sufficient conditions
</p>
</li>
<li><p><b></b>Lec 12 (Feb 13):<b></b> Gradient descent and line search method
</p>
</li>
<li><p><b></b>Lec 13 (Feb 18):<b></b> Condition number and preconditioned gradient descent
</p>
</li>
<li><p><b></b>Lec 14 (Feb 20):<b></b> Newton’s method
</p>
</li>
<li><p><b></b>Lec 15 (Feb 25):<b></b> Quasi Newton method
</p>
</li>
<li><p><b></b>Lec 16 (Feb 27):<b></b> Rates of convergence for GD
</p>
</li>
<li><p><b></b>Lec 17 (Mar 4):<b></b> No Lecture today
</p>
</li>
<li><p><b></b>Lec 18 (Mar 6):<b></b> (No topic assigned)
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-12-26 15:13:39 CST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
